# -*- coding: utf-8 -*-
"""RekomenadasiManhwa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fWxvhZN8gV-a4RM349_-kCIDiIED0-oN

# Source Dataset
kaggle https://www.kaggle.com/datasets/iridazzle/webtoon-originals-datasets?select=webtoon_originals_id.csv
"""

!pip install Sastrawi

# prompt: downlaod  https://www.kaggle.com/datasets/iridazzle/webtoon-originals-datasets?select=webtoon_originals_id.csv

!pip install kaggle

# Replace with your actual Kaggle API key
!mkdir -p ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d iridazzle/webtoon-originals-datasets -f webtoon_originals_en.csv
!unzip webtoon_originals_en.csv.zip

!pip install gensim

!pip install gradio

# Import necessary libraries
import pandas as pd
import numpy as np
import gradio as gr
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from sklearn.decomposition import TruncatedSVD
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from tqdm import tqdm
import torch
from transformers import AutoTokenizer, AutoModel
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.io as pio

"""#Exploratory Data Analyst"""

df = pd.read_csv('/content/webtoon_originals_en.csv')
df

#Data Information
df.info()

# Visualisasi 1: Distribusi Genre
genre_counts = df['genre'].value_counts().reset_index()
genre_counts.columns = ['genre', 'count']
fig1 = px.bar(genre_counts, x='genre', y='count',
              title='Distribusi Genre Webtoon',
              labels={'genre': 'Genre', 'count': 'Jumlah'},
              color='genre', color_discrete_sequence=px.colors.qualitative.Dark24)
fig1.update_xaxes(categoryorder='total descending')

# Visualisasi 2: Distribusi Panjang Judul Webtoon
df['title_length'] = df['title'].apply(len)
fig2 = px.histogram(df, x='title_length', nbins=20,
                    title='Distribusi Panjang Judul Webtoon',
                    labels={'title_length': 'Jumlah Karakter Judul'},
                    color_discrete_sequence=['#636EFA'])

# Visualisasi 3: Rating vs Views
fig3 = px.scatter(df, x='rating', y='views', size='subscribers', color='genre',
                  title='Hubungan Rating dengan Views',
                  labels={'rating': 'Rating', 'views': 'Views'},
                  color_discrete_sequence=px.colors.qualitative.Safe)

# Visualisasi 4: Perbandingan Engagement Berdasarkan Status
fig4 = px.box(df, x='status', y='views', color='status',
              title='Distribusi Views Berdasarkan Status Webtoon',
              color_discrete_sequence=px.colors.qualitative.Bold)

# Visualisasi 5: Pengaruh Daily Pass terhadap Subscribers
fig5 = px.box(df, x='daily_pass', y='subscribers', color='daily_pass',
              title='Perbandingan Subscribers Berdasarkan Daily Pass',
              color_discrete_sequence=['blue', 'red'])

# Menyimpan semua visualisasi dalam satu file HTML
fig = make_subplots(rows=3, cols=2,
                    subplot_titles=["Distribusi Genre", "Distribusi Panjang Judul Webtoon",
                                    "Rating vs Views", "Status vs Views",
                                    "Daily Pass vs Subscribers"],
                    vertical_spacing=0.2, horizontal_spacing=0.15)

for i, figure in enumerate([fig1, fig2, fig3, fig4, fig5]):
    for trace in figure.data:
        fig.add_trace(trace, row=(i//2)+1, col=(i%2)+1)

fig.update_layout(title_text="Analisis Data Webtoon", height=1200, width=1400, showlegend=False)
pio.write_html(fig, "webtoon_analysis1.html")

print("Semua visualisasi telah diperbaiki, dirapikan, dan disimpan dalam webtoon_analysis.html.")

# TF-IDF Model
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(df['synopsis'])
cosine_sim_tfidf = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Transformers (Sentence-BERT)
sbert_model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = sbert_model.encode(df['synopsis'].tolist(), convert_to_tensor=True)
cosine_sim_sbert = cosine_similarity(embeddings.cpu().numpy())

# Latent Semantic Analysis (LSA)
lsa = TruncatedSVD(n_components=100)
lsa_matrix = lsa.fit_transform(tfidf_matrix)
cosine_sim_lsa = cosine_similarity(lsa_matrix, lsa_matrix)

# Doc2Vec Model
documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(df['synopsis'])]
doc2vec_model = Doc2Vec(documents, vector_size=100, window=5, min_count=2, workers=4, epochs=20)
doc_vectors = np.array([doc2vec_model.infer_vector(doc.words) for doc in documents])
cosine_sim_doc2vec = cosine_similarity(doc_vectors, doc_vectors)

# Deep Learning Model (Transformer Fine-Tuning)
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
model = AutoModel.from_pretrained("bert-base-uncased")

def get_bert_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state[:, 0, :].numpy()

bert_embeddings = np.array([get_bert_embedding(text) for text in tqdm(df['synopsis'])])
cosine_sim_bert = cosine_similarity(bert_embeddings.reshape(len(df), -1))

def get_recommendations(title, model_type):
    similarity_matrices = {
        "TF-IDF": cosine_sim_tfidf,
        "SBERT": cosine_sim_sbert,
        "LSA": cosine_sim_lsa,
        "Doc2Vec": cosine_sim_doc2vec,
        "BERT": cosine_sim_bert
    }

    if title not in df['title'].values:
        return "Title not found in dataset"

    idx = df[df['title'] == title].index[0]
    scores = list(enumerate(similarity_matrices[model_type][idx]))
    scores = sorted(scores, key=lambda x: x[1], reverse=True)
    top_indices = [i[0] for i in scores[1:6]]
    return df.iloc[top_indices][['title', 'genre', 'rating']]

def recommend(title, model_type):
    recommendations = get_recommendations(title, model_type)
    return recommendations.to_markdown()

from sklearn.metrics import ndcg_score, precision_score, recall_score
def evaluate_recommendations(model_type):
    similarity_matrices = {
        "TF-IDF": cosine_sim_tfidf,
        "SBERT": cosine_sim_sbert,
        "LSA": cosine_sim_lsa,
        "Doc2Vec": cosine_sim_doc2vec,
        "BERT": cosine_sim_bert
    }

    relevance_scores = []
    for idx in range(len(df)):
        scores = list(enumerate(similarity_matrices[model_type][idx]))
        scores = sorted(scores, key=lambda x: x[1], reverse=True)
        top_indices = [i[0] for i in scores[1:6]]
        relevance = [1 if df.iloc[i]['genre'] == df.iloc[idx]['genre'] else 0 for i in top_indices]
        relevance_scores.append(relevance)

    ndcg = np.mean([ndcg_score([rel], [list(range(len(rel)))]) for rel in relevance_scores])
    precision = np.mean([precision_score([1] * len(rel), rel, zero_division=1) for rel in relevance_scores])
    recall = np.mean([recall_score([1] * len(rel), rel, zero_division=1) for rel in relevance_scores])

    return {"NDCG": ndcg, "Precision": precision, "Recall": recall}

# Evaluasi di luar Gradio
for model in ["TF-IDF", "SBERT", "LSA", "Doc2Vec", "BERT"]:
    print(f"Evaluasi untuk model {model}:", evaluate_recommendations(model))

# Tambahkan Bootstrap & CSS
custom_css = """
<style>
    body {
        background-color: #f8f9fa;
    }
    .container {
        max-width: 700px;
        margin: 20px auto;
        padding: 20px;
        background-color: white;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
    }
    .gradio-container {
        font-family: 'Arial', sans-serif;
    }
</style>
"""

# Gradio Interface dengan Bootstrap
iface = gr.Interface(
    fn=recommend,
    inputs=[
        gr.Dropdown(choices=df['title'].tolist(), label="ðŸ“š Pilih Judul Webtoon"),
        gr.Radio(["TF-IDF", "SBERT", "LSA", "Doc2Vec", "BERT"], label="ðŸ¤– Pilih Model Rekomendasi")
    ],
    outputs=gr.Markdown(label="âœ¨ Rekomendasi Judul Webtoon"),
    title="ðŸš€ Sistem Rekomendasi Webtoon",
    description="Pilih judul webtoon dan model rekomendasi untuk mendapatkan saran webtoon serupa.",
    theme="default",
)

# Tambahkan custom HTML + Bootstrap
iface.launch(share=True)  # Gunakan share=True agar bisa dibuka dari Colab